import numpy as np
import sympy as sp

from scipy.stats import f, t, chi2, norm


def distribution(thetas, variance, n, m, distrib_type='normal'):
    """
    Генерирует данные для модели линейной регрессии с заданными параметрами
    distrib_type - тип распределения случайной ошибки ('normal' для нормального распределения и 'uniform' для равномерного распределения)
    Пояснение шагов функции:
    1. Устанавливается seed для генератора случайных чисел для воспроизводимости результатов;
    2. Выбираются первые m+1 коэффициентов из thetas;
    3. Генерируется вектор x_k с равномерно распределенными значениями от -4 до 4;
    4. Создается матрица признаков X;
    5. В зависимости от типа распределения случайной ошибки (distrib_type) генерируется случайная ошибка с нулевым средним и заданной дисперсией для   нормального распределения или с равномерным распределением в заданном диапазоне;
    6. Генерируются зависимые переменные y(наш набор наблюдений) с использованием уравнения линейной регрессии X @ thetas + noise;
    7. Возвращаются матрица признаков X и зависимая переменная y.
    """
    np.random.seed(seed=21) 
    thetas = thetas[:m+1]
    x_k  = -4 + np.arange(1, n+1) * 8/n
    X = np.vander(x_k, m + 1, increasing=True)
    
    if distrib_type == 'normal':
        noise = np.random.normal(0, np.sqrt(variance), n)
    else:
        noise = np.random.uniform(-3 * np.sqrt(variance), 3 * np.sqrt(variance), n)
    
    y = X @ thetas + noise
    
    return X, y

def vector_w(X, y):
    """
    Вычисляет вектор весов w для модели линейной регрессии, то есть это массив наших значений thetas
    """
    return np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)

def fisher_test(X, y, thetas, alpha, m_value, distrib='normal'):
    """
    Выполняет статистический тест Фишера для проверки значимости добавления или удаления группы признаков в модели линейной регрессии
    Алгоритм:
    1. Функция вычисляет вектор весов w с помощью вызова функции vector_w с использованием сгенерированных данных X и y;
    2. Затем вычисляется статистика Фишера по формуле, используя полученные веса w, матрицу признаков X, зависимую переменную y, количество наблюдений n и количество признаков m_value;
    3. Также вычисляется теоретическое значение критерия Фишера с помощью функции f.ppf;
    4. Затем происходит сравнение вычисленной статистики Фишера с теоретическим значением критерия Фишера. Если абсолютное значение статистики больше критического значения, то гипотеза отвергается;
    5. В зависимости от результата теста, функция выводит информацию о том, была ли отвергнута гипотеза и возвращает соответствующее булево значение.
    """
    variance = 3
    n = 40
    if distrib == 'normal':
        X, y = distribution(thetas, variance, n, m_value)
    else:
        X, y = distribution(thetas, variance, n, m_value, 'uniform')
    w = vector_w(X, y)
    
    # Вычисляем статистику Фишера
    r_m = np.diag(np.linalg.inv(X.T @ X))[-1]
    stat = ((n - m_value) *  w[-1]**2) / ((r_m) * np.linalg.norm(y - X @ w)**2)
    # Теор. значение критерия Фишера
    crit_value = f.ppf(1 - alpha, 1, n - m_value)
    print('Критическое значение = ', crit_value)
    print('Значение Фишера = ', stat)
    if np.abs(stat) > crit_value:
        print(f"Гипотеза при m={m_value} отвергается")
        return True
    else:
        print(f"Гипотеза при m={m_value} принимается")
        return False
        
def confidence_interval_firts(X, y, w, n, m, alpha):
    """
    Вычисляет доверительные интервалы для параметров модели линейной регрессии
    Алгоритм:
    1. В начале функции вычисляется квантиль распределения стьюдента quant с помощью функции t.ppf;
    2. Затем вычисляется диагональная матрица r, обратная к матрице признаков X;
    3. Затем вычисляется остаточная сумма квадратов residual и вектор delta, содержащий длины доверительных интервалов для параметров модели;
    4. Затем функция выводит на экран доверительные интервалы для каждого параметра модели.
    """
    # Вычисляем квантиль распределения стьюдента
    quant = t.ppf(1 - (1 - alpha) / 2, n - m - 1)
    
    r = np.diag(np.linalg.inv(X.T @ X))
    
    residual = np.linalg.norm(y - X @ w)
    
    delta = quant * residual * np.sqrt(r/(n-m))
    
    for i, theta in enumerate(w):
        print(f"Доверительный интервал для theta_{i} = {theta:.2f}:")
        print(f"({theta - delta[i]}, {theta + delta[i]})")

def confidence_interval_second(X, y, w, n, m, alpha, pr=True):
    """
    Вычисляет доверительные интервалы для параметров модели линейной регрессии
    Алгоритм:
    1. В начале функции вычисляется квантиль распределения стьюдента quant с помощью функции t.ppf. Это значение используется для вычисления доверительного интервала;
    2. Затем создается символьная переменная symb_x с помощью sp.symbols("x"), которая используется для создания матрицы признаков x с помощью библиотеки SymPy;
    4. Создается матрица признаков X;
    4. Затем предсказанные значения зависимой переменной y_pred вычисляются как произведение матрицы признаков x на вектор параметров модели w;
    5. Далее вычисляется диагональная матрица r, обратная к матрице признаков X. Это используется для вычисления длины доверительного интервала;
    6. Вычисляется вектор delta, содержащий длину доверительного интервала для зависимой переменной;
    7. Если параметр pr равен True, то функция выводит на экран доверительный интервал для зависимой переменной;
    8. В конце функция возвращает значение delta, которое представляет собой длину доверительного интервала.
    """
    # Вычисляем квантиль распределения стьюдента
    quant = t.ppf(1 - (1 - alpha) / 2, n - m - 1)
    
    symb_x = sp.symbols("x")
    x = sp.Matrix(np.vander(np.array([symb_x]), m + 1, increasing=True))
    y_pred = x * sp.Matrix(w)
    
    r = sp.simplify(sp.sqrt((x * np.linalg.inv(np.dot(X.T, X)) * x.T))[0,0] / np.sqrt(n-m))
    
    delta = np.linalg.norm(y - X @ w) * r * quant

    if pr:        
        print("Доверительный интервал:")
        print(f"{y_pred[0]} +-: \t")
        print(f"({delta})")
    
    return delta

def criteria_pirson(x, y, y_pred, n, alpha):
    """
    Критерий Пирсона для проверки гипотезы о нормальности распределения остатков в модели линейной регрессии
    Алгоритм:
    1. В начале функции вычисляется разность между фактическими значениями зависимой переменной y и предсказанными значениями y_pred;
    2. Затем определяется количество интервалов гистограммы num_bins с использованием формулы int(3.32 * np.log10(n)) + 1, где n - количество наблюдений;
    3. С помощью функции np.histogram вычисляется гистограмма разностей и их границы;
    4. Вычисляется ширина каждого интервала гистограммы bin_width;
    5. Оцениваются ожидаемые частоты expected_freq с использованием функции распределения нормального закона, а также фактические частоты estimated_freq;
    6. Вычисляется статистика критерия Пирсона estimated_value на основе оцененных и ожидаемых частот;
    7. Вычисляется критическое значение для распределения хи-квадрат с помощью функции chi2.ppf;
    8. Если значение статистики критерия Пирсона меньше или равно критическому значению, то выводится сообщение о принятии гипотезы о нормальности распределения остатков, в противном случае - сообщение об отвержении этой гипотезы.
    """
    diff = y - y_pred
    num_bins = int(np.log2(n)) + 1
    hist, bin_edges = np.histogram(diff, bins=num_bins, density=True)
    
    bin_width = bin_edges[1] - bin_edges[0]
    expected_freq = np.diff([0] + list(norm.cdf(bin_edges, loc=0, scale=(np.sum(diff**2) / n))) + [1])
    estimated_freq = [0] + list(hist * bin_width) + [0]
    
    estimated_value = n * np.sum((estimated_freq - expected_freq)**2 / expected_freq)
    critical_value = chi2.ppf(1 - alpha, df=num_bins)

    print('Критическое значение = ', critical_value)
    print('Значение Пирсона = ', estimated_value)
    if estimated_value <= critical_value:
        print("Принимаем гипотезу о нормальности распределения остатков.")
    else:
        print("Отвергаем гипотезу о нормальности распределения остатков.")